# -*- coding: utf-8 -*-
"""phishing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eFYfiB4tDlcQMzPAgVnDZ7Ch9uCRbycH
"""

import pandas as pd
import matplotlib.pyplot as plt
import pandas as pd

from tensorflow import keras
from tensorflow.keras.layers import Dense,Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.callbacks import EarlyStopping

df = pd.read_csv("phishing_site_urls.csv")

df

df["Label"] = df["Label"].apply(lambda x: 1 if x == "bad" else 0)

df[df["Label"]==0]

df.info()

df.describe()

# Count the number of data in each label
label_counts = df['Label'].value_counts()
label_counts

# Define colors based on label value
colors = ['green' if val == 0 else 'red' for val in label_counts.index]

# Create a bar chart
plt.bar(label_counts.index, label_counts.values, color=colors)
plt.xlabel('Label')
plt.ylabel('Number of Data')
plt.title('Number of Data by Label')
plt.show()

# Identify minority class and count
minority_class = label_counts.idxmin()
minority_count = label_counts.min()

# Filter data to keep only minority class and a random sample of the majority class to match minority count
df_balanced = pd.concat([df[df['Label'] == minority_class], df[df['Label'] != minority_class].sample(minority_count)])
df_balanced

# Count the number of data in each label
label_counts = df_balanced['Label'].value_counts()
label_counts

# Define colors based on label value
colors = ['green' if val == 0 else 'red' for val in label_counts.index]

# Create a bar chart
plt.bar(label_counts.index, label_counts.values, color=colors)
plt.xlabel('Label')
plt.ylabel('Number of Data')
plt.title('Number of Data by Label')
plt.show()

df=df_balanced

y = df["Label"].to_numpy()
X = df["URL"]

tokenizer = Tokenizer()
tokenizer.fit_on_texts(X)
sequences = tokenizer.texts_to_sequences(X)

max_len = max(len(seq) for seq in sequences)
X_features = pad_sequences(sequences, maxlen=max_len)

model = Sequential()

# Input layer with number of features
model.add(Dense(units=16, activation="relu", input_dim=X_features.shape[1]))

# Hidden Layers
# model.add(Dense(units=32, activation="relu"))

model.add(Dense(units=64, activation="relu"))

model.add(Dense(units=128, activation="relu"))

model.add(Dense(units=64, activation="relu"))

# model.add(Dense(units=32, activation="relu"))

model.add(Dense(units=16, activation="relu"))

# Output layer for binary classification
model.add(Dense(units=1, activation="sigmoid"))

early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)

model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])
history = model.fit(X_features, y, epochs=100, batch_size=16, validation_split=0.2, callbacks=[early_stopping])

plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.xlabel('Epochs')
plt.ylabel('Loss Value')
plt.title('Training Metrics')
plt.legend()
plt.show()

plt.plot(history.history['accuracy'], label='train_accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy Value')
plt.title('Training Metrics')
plt.legend()
plt.show()

model.summary()

def preprocess_url(new_url):
    # Tokenize the new URL
    new_sequence = tokenizer.texts_to_sequences([new_url])
    # Pad the sequence
    new_sequence_padded = pad_sequences(new_sequence, maxlen=max_len)
    return new_sequence_padded

def predict_url(new_url):
    # Preprocess the new URL
    new_sequence_padded = preprocess_url(new_url)
    # Make a prediction
    prediction = model.predict(new_sequence_padded)
    # Return the predicted label
    return 'bad' if prediction[0][0] > 0.5 else 'good'

new_url = "chenowethsite.com/chennmc5.htm"
predicted_label = predict_url(new_url)
print(f"The URL '{new_url}' is predicted to be '{predicted_label}'")

new_url = "www.dghjdgf.com/paypal.co.uk/cycgi-bin/webscrcmd=_home-customer&nav=1/loading.php"
predicted_label = predict_url(new_url)
print(f"The URL '{new_url}' is predicted to be '{predicted_label}'")

model.save('phishing_model.h5')

import pickle
with open('phishing_tokenizer.pkl', 'wb') as handle:
    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)

from google.colab import files

# Download the model
files.download('phishing_model.h5')

# Download the tokenizer
files.download('phishing_tokenizer.pkl')